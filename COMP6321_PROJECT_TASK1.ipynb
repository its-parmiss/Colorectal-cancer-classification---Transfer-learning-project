{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Library Import**"
      ],
      "metadata": {
        "id": "AtePWsI-wfX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hbaUWA-ZwGDe"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from torchvision import transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Drive**"
      ],
      "metadata": {
        "id": "JbBHlniMwk-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6_BVFW8wOtZ",
        "outputId": "9fb8576c-958f-49e8-a1ed-2807f146210a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Path Do Task1 Dataset ( Colorectal Cancer )**"
      ],
      "metadata": {
        "id": "tU_h3u4xyjN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colorectral_dataset_path = \"/content/drive/MyDrive/Comp6321 project dataset/Colorectal Cancer\""
      ],
      "metadata": {
        "id": "cgb_avEMwufg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Torchvision Imagefolder dataset**"
      ],
      "metadata": {
        "id": "PdFNafkczNH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size as needed\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "colorectral_dataset = ImageFolder(root=colorectral_dataset_path, transform=transform)"
      ],
      "metadata": {
        "id": "ggHuWvB2zAAI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train, test, validation splitting**"
      ],
      "metadata": {
        "id": "eS6SOeyw8Epe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 70% Training, 15% Validation, 15% Testing\n",
        "train_size = int(0.7 * len(colorectral_dataset))\n",
        "val_size = int(0.15 * len(colorectral_dataset))\n",
        "test_size = len(colorectral_dataset) - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset, test_dataset = random_split(colorectral_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Now you can create your dataloaders dictionary\n",
        "colorectral_dataloaders = {'train': train_dataloader, 'val': val_dataloader, 'test': test_dataloader}\n",
        "\n",
        "# And your dataset_sizes dictionary\n",
        "colorectral_dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}"
      ],
      "metadata": {
        "id": "zWbUEIL17_h1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Colorectral Cancer Detection Class**"
      ],
      "metadata": {
        "id": "XTepOMz52S0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import models\n",
        "import time\n",
        "import copy\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def create_model(self):\n",
        "        # Create a ResNet model without pretraining\n",
        "        model = models.resnet50(weights=None)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, self.num_classes)\n",
        "        return model.to(self.device)\n",
        "\n",
        "    def get_loss(self):\n",
        "        # Define the criterion\n",
        "        return nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_optimizer(self, model):\n",
        "        # Observe that all parameters are being optimized\n",
        "        return optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    def get_scheduler(self, optimizer):\n",
        "        # Decay LR by a factor of 0.1 every 7 epochs\n",
        "        return lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    def train_model(self, model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=11):\n",
        "        since = time.time()\n",
        "\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model\n",
        "\n",
        "    def run(self, dataloaders, dataset_sizes):\n",
        "        model = self.create_model()\n",
        "        criterion = self.get_loss()\n",
        "        optimizer = self.get_optimizer(model)\n",
        "        scheduler = self.get_scheduler(optimizer)\n",
        "        self.train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes)\n"
      ],
      "metadata": {
        "id": "oiVbazmqzgOq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training a ResNet-50 from scratch - Three Classes**"
      ],
      "metadata": {
        "id": "dg9hhju83Xar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "classifier = ImageClassifier(num_classes=num_classes)\n",
        "classifier.run(colorectral_dataloaders, colorectral_dataset_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyenGWFu2bup",
        "outputId": "1a358f61-b9bd-48ae-ee5b-2ea78a130a45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/10\n",
            "----------\n",
            "train Loss: 0.9991 Acc: 0.5583\n",
            "val Loss: 0.6188 Acc: 0.7733\n",
            "\n",
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 0.6945 Acc: 0.7133\n",
            "val Loss: 0.5034 Acc: 0.8244\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.5277 Acc: 0.7940\n",
            "val Loss: 0.4500 Acc: 0.8122\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.4822 Acc: 0.8157\n",
            "val Loss: 0.3666 Acc: 0.8633\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.4047 Acc: 0.8414\n",
            "val Loss: 0.4847 Acc: 0.8544\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.3966 Acc: 0.8462\n",
            "val Loss: 0.3575 Acc: 0.8589\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.3182 Acc: 0.8762\n",
            "val Loss: 0.3421 Acc: 0.8900\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.2354 Acc: 0.9079\n",
            "val Loss: 0.1744 Acc: 0.9400\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.2146 Acc: 0.9179\n",
            "val Loss: 0.1729 Acc: 0.9333\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.2080 Acc: 0.9217\n",
            "val Loss: 0.1653 Acc: 0.9367\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.2020 Acc: 0.9238\n",
            "val Loss: 0.1614 Acc: 0.9422\n",
            "\n",
            "Training complete in 10m 55s\n",
            "Best val Acc: 0.942222\n"
          ]
        }
      ]
    }
  ]
}